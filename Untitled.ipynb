{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\nikee\\anaconda3\\lib\\site-packages (from pydot) (2.4.7)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout \n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing import image\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/nikee/Desktop/cnn_ball_clasification/data/train'\n",
    "test_path = 'C:/Users/nikee/Desktop/cnn_ball_clasification/data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator,img_to_array,array_to_img,load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 662 images belonging to 7 classes.\n",
      "Found 7 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data Augmentation \n",
    "\n",
    "train_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale= 1/255.,                                                                                                                   \n",
    "                                                           rotation_range=0.2,\n",
    "                                                           width_shift_range=0.2,\n",
    "                                                           height_shift_range=0.2,\n",
    "                                                           zoom_range = 0.2, \n",
    "                                                           horizontal_flip=True,\n",
    "                                                           validation_split = 0.25\n",
    "                                                            )\n",
    "test_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale= 1/255.,\n",
    "                                                          validation_split = 0.25\n",
    "                                                          )\n",
    "\n",
    "train_data = train_gen.flow_from_directory(train_path,\n",
    "                                           target_size = (224,224),\n",
    "                                           class_mode = \"categorical\",\n",
    "                                           batch_size = 32,\n",
    "                                           classes = [\"baseball\", \"basketball\", \"bowling ball\", \"cricket ball\", \"football\", \"golf ball\", \"tennis ball\"],\n",
    "                                           seed = 42,\n",
    "                                           subset = \"training\"                                           \n",
    "                                           )\n",
    "test_data = test_gen.flow_from_directory(test_path,\n",
    "                                         target_size = (224,224),\n",
    "                                         class_mode = \"categorical\",\n",
    "                                         classes = [\"baseball\", \"basketball\", \"bowling ball\", \"cricket ball\", \"football\", \"golf ball\", \"tennis ball\"],\n",
    "                                         batch_size = 32,\n",
    "                                         seed = 42,\n",
    "                                         subset = \"validation\"\n",
    "                                         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baseball',\n",
       " 'basketball',\n",
       " 'bowling ball',\n",
       " 'cricket ball',\n",
       " 'football',\n",
       " 'golf ball',\n",
       " 'tennis ball']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = list(train_data.class_indices.keys())\n",
    "\n",
    "class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n",
      "(32, 7)\n"
     ]
    }
   ],
   "source": [
    "image,label = train_data.next()\n",
    "print(image.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a cnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             layers.Conv2D(filters=64, kernel_size= 2, activation=\"relu\", input_shape=(224,224,3)),\n",
    "                             layers.MaxPooling2D(pool_size= 2),\n",
    "\n",
    "                             layers.Conv2D(filters= 64, kernel_size= 2, activation=\"relu\"),\n",
    "                             layers.MaxPooling2D(pool_size= 2),\n",
    "\n",
    "                             layers.Conv2D(filters= 64, kernel_size= 2, activation= \"relu\"),\n",
    "                             layers.MaxPooling2D(pool_size = 2),\n",
    "\n",
    "                            layers.Conv2D(filters= 64, kernel_size= 2, activation= \"relu\"),\n",
    "                             layers.MaxPooling2D(pool_size = 2),\n",
    "\n",
    "                             layers.Flatten(),\n",
    "\n",
    "                             layers.Dense(128, activation= \"relu\"),\n",
    "                             layers.Dropout(0.5),\n",
    "                             layers.Dense(7, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = tf.keras.losses.categorical_crossentropy,\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "21/21 [==============================] - 84s 4s/step - loss: 1.8541 - accuracy: 0.2553 - val_loss: 1.4036 - val_accuracy: 0.5714\n",
      "Epoch 2/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 1.5204 - accuracy: 0.4215 - val_loss: 1.1285 - val_accuracy: 0.5714\n",
      "Epoch 3/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 1.2478 - accuracy: 0.5785 - val_loss: 0.7448 - val_accuracy: 0.7143\n",
      "Epoch 4/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 1.1711 - accuracy: 0.5891 - val_loss: 0.7450 - val_accuracy: 0.7143\n",
      "Epoch 5/25\n",
      "21/21 [==============================] - 72s 3s/step - loss: 1.0928 - accuracy: 0.6450 - val_loss: 0.6747 - val_accuracy: 0.8571\n",
      "Epoch 6/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 1.0601 - accuracy: 0.6329 - val_loss: 0.5784 - val_accuracy: 0.8571\n",
      "Epoch 7/25\n",
      "21/21 [==============================] - 72s 3s/step - loss: 1.0144 - accuracy: 0.6495 - val_loss: 0.4617 - val_accuracy: 0.8571\n",
      "Epoch 8/25\n",
      "21/21 [==============================] - 67s 3s/step - loss: 0.9305 - accuracy: 0.6843 - val_loss: 0.4461 - val_accuracy: 0.8571\n",
      "Epoch 9/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 0.9454 - accuracy: 0.7024 - val_loss: 0.6056 - val_accuracy: 0.7143\n",
      "Epoch 10/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 0.9146 - accuracy: 0.6934 - val_loss: 0.5042 - val_accuracy: 0.8571\n",
      "Epoch 11/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 0.9223 - accuracy: 0.6752 - val_loss: 0.5419 - val_accuracy: 0.8571\n",
      "Epoch 12/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 0.8244 - accuracy: 0.7009 - val_loss: 0.3985 - val_accuracy: 0.8571\n",
      "Epoch 13/25\n",
      "21/21 [==============================] - 80s 4s/step - loss: 0.7862 - accuracy: 0.7341 - val_loss: 0.6505 - val_accuracy: 0.8571\n",
      "Epoch 14/25\n",
      "21/21 [==============================] - 78s 4s/step - loss: 0.7506 - accuracy: 0.7538 - val_loss: 0.4787 - val_accuracy: 0.8571\n",
      "Epoch 15/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 0.7547 - accuracy: 0.7417 - val_loss: 0.4850 - val_accuracy: 0.8571\n",
      "Epoch 16/25\n",
      "21/21 [==============================] - 73s 3s/step - loss: 0.6921 - accuracy: 0.7900 - val_loss: 0.3647 - val_accuracy: 0.8571\n",
      "Epoch 17/25\n",
      "21/21 [==============================] - 72s 3s/step - loss: 0.6401 - accuracy: 0.7900 - val_loss: 0.6047 - val_accuracy: 0.8571\n",
      "Epoch 18/25\n",
      "21/21 [==============================] - 72s 3s/step - loss: 0.7176 - accuracy: 0.7613 - val_loss: 0.4187 - val_accuracy: 0.8571\n",
      "Epoch 19/25\n",
      "21/21 [==============================] - 73s 3s/step - loss: 0.7322 - accuracy: 0.7659 - val_loss: 0.6383 - val_accuracy: 0.7143\n",
      "Epoch 20/25\n",
      "21/21 [==============================] - 72s 3s/step - loss: 0.7295 - accuracy: 0.7689 - val_loss: 0.4866 - val_accuracy: 0.8571\n",
      "Epoch 21/25\n",
      "21/21 [==============================] - 73s 3s/step - loss: 0.6534 - accuracy: 0.7810 - val_loss: 0.4149 - val_accuracy: 0.8571\n",
      "Epoch 22/25\n",
      "21/21 [==============================] - 73s 3s/step - loss: 0.6449 - accuracy: 0.7855 - val_loss: 0.6471 - val_accuracy: 0.8571\n",
      "Epoch 23/25\n",
      "21/21 [==============================] - 73s 3s/step - loss: 0.5975 - accuracy: 0.7931 - val_loss: 0.6485 - val_accuracy: 0.8571\n",
      "Epoch 24/25\n",
      "21/21 [==============================] - 73s 3s/step - loss: 0.6029 - accuracy: 0.7961 - val_loss: 0.5056 - val_accuracy: 0.8571\n",
      "Epoch 25/25\n",
      "21/21 [==============================] - 71s 3s/step - loss: 0.6803 - accuracy: 0.7840 - val_loss: 0.2588 - val_accuracy: 0.8571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2430951f220>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data,\n",
    "          epochs = 25,\n",
    "         # steps_per_epoch = len(train_data),\n",
    "          validation_data = test_data,\n",
    "         # validation_steps = len(test_data)\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_yaml = model.to_json()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:/Users/nikee/Desktop/cnn_ball_clasification/data/valid/baseball/1.jpg\n",
    "    \n",
    "    \n",
    "    baseball',\n",
    " 'basketball',\n",
    " 'bowling ball',\n",
    " 'cricket ball',\n",
    " 'football',\n",
    " 'golf ball',\n",
    " 'tennis ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = 'model.sav'\n",
    "#pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://55f62136-b8ea-4cf0-b4ff-240c8f3e4e4c/assets\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e5484904a374>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#filename = 'Regressor_0.sav'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#pickle.dump(Regressor_0, open(filename, 'wb'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__reduce__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m       return (pickle_utils.deserialize_model_from_bytecode,\n\u001b[1;32m--> 315\u001b[1;33m               pickle_utils.serialize_model_as_bytecode(self))\n\u001b[0m\u001b[0;32m    316\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m       \u001b[1;31m# SavedModel (and hence serialize_model_as_bytecode) only support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\saving\\pickle_utils.py\u001b[0m in \u001b[0;36mserialize_model_as_bytecode\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m           \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTarInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m           \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m           \u001b[0marchive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36msize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;34m\"\"\"Returns the size of the file.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mstat\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    908\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m   \"\"\"\n\u001b[1;32m--> 910\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mstat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mstat_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m   \"\"\"\n\u001b[1;32m--> 926\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_file_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_to_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "#filename = 'Regressor_0.sav'\n",
    "#pickle.dump(Regressor_0, open(filename, 'wb'))\n",
    "pickle.dump(model, open(\"model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model_flow.png', show_shapes=True, show_layer_names=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
